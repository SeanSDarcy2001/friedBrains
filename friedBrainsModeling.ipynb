{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "friedBrainsModeling.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPEmcRKsB6r6XQwXNwRKtcQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeanSDarcy2001/friedBrains/blob/main/friedBrainsModeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "imports"
      ],
      "metadata": {
        "id": "q4cOTwsv_amw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jRk530g4_Jd3"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification, make_regression\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data simulation"
      ],
      "metadata": {
        "id": "sWCci3J1_i41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for sober/intoxicated classifier\n",
        "\n",
        "features, output = make_classification(n_samples = 1000,\n",
        "                                       n_features = 3,\n",
        "                                       n_informative= 3,\n",
        "                                       n_redundant=0,\n",
        "                                       n_classes = 2,\n",
        "                                       weights = [0.75, 0.25])\n",
        "\n",
        "#weights are for class generation. Roughly expect to play sober 90% of the time and intoxicated the other 10%\n",
        "\n",
        "print(pd.DataFrame(features, columns=['Reaction Time', 'Accuracy', 'Literally Anything Else']).head())\n",
        "print(pd.DataFrame(output, columns=['Class']))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_OEWzk8_lOp",
        "outputId": "5dd510f8-f0be-4f7d-bcaa-557ed21d3a46"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Reaction Time  Accuracy  Literally Anything Else\n",
            "0       1.253769  0.906094                 1.945247\n",
            "1      -0.649110 -1.528401                -0.384830\n",
            "2       1.675395  0.248165                 1.314595\n",
            "3      -1.336068 -2.152434                -1.735630\n",
            "4      -0.028392  1.538973                 2.527456\n",
            "     Class\n",
            "0        0\n",
            "1        0\n",
            "2        0\n",
            "3        0\n",
            "4        1\n",
            "..     ...\n",
            "995      0\n",
            "996      0\n",
            "997      0\n",
            "998      1\n",
            "999      0\n",
            "\n",
            "[1000 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mlp\n",
        "\n",
        "class MLP(nn.Module) :\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(3, 9, bias=True)\n",
        "        self.h1 = nn.Linear(9, 3, bias=True)\n",
        "        self.h2 = nn.Linear(3, 2, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.l1(x))\n",
        "        x = torch.sigmoid(self.h1(x))\n",
        "        x = torch.sigmoid(self.h2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "uO5xqXDXza5d"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install skorch\n",
        "from skorch import NeuralNetClassifier\n",
        "\n",
        "\n",
        "    \n",
        "features = features.astype(np.float32)\n",
        "output = output.astype(np.int64)\n",
        "\n",
        "\n",
        "trainFraction = .8\n",
        "sample = np.random.uniform(size = 1000) < trainFraction\n",
        "xtrain = features[sample]\n",
        "ytrain = output[sample]\n",
        "xtest = features[~sample]\n",
        "ytest = output[~sample]\n",
        "\n",
        "#ytrain = torch.tensor(ytrain).float()\n",
        "#ytest = torch.tensor(ytest).float()\n",
        "\n",
        "xtorch = torch.from_numpy(xtrain).float()\n",
        "ytorch = torch.from_numpy(ytrain).float().unsqueeze(1)\n",
        "\n",
        "learning_rate = 1.25\n",
        "model = MLP()\n",
        "\n",
        "def init_weights(m):\n",
        "  if isinstance(m, nn.Linear):\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "    m.bias.data.fill_(0.01)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "net = NeuralNetClassifier(model, max_epochs = 100, lr = learning_rate, iterator_train__shuffle = True)\n",
        "net.fit(xtrain, ytrain)\n",
        "\n",
        "preds = net.predict(xtest)\n",
        "acc = 0\n",
        "tot = 0\n",
        "for i in range(len(preds)) :\n",
        "  if preds[i] == ytest[i] :\n",
        "    acc += 1\n",
        "    tot += 1\n",
        "  else :\n",
        "    tot += 1\n",
        "print(\"MLP Test Accuracy:\", acc/tot)\n"
      ],
      "metadata": {
        "id": "wHTO359y0yq_",
        "outputId": "95cf82b5-ab49-4fbf-a091-a745ff38ab2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.3558\u001b[0m       \u001b[32m0.7484\u001b[0m        \u001b[35m0.1382\u001b[0m  0.0112\n",
            "      2        \u001b[36m0.1045\u001b[0m       0.7484        \u001b[35m0.0696\u001b[0m  0.0120\n",
            "      3        \u001b[36m0.0580\u001b[0m       0.7484        \u001b[35m0.0445\u001b[0m  0.0120\n",
            "      4        \u001b[36m0.0389\u001b[0m       0.7484        \u001b[35m0.0320\u001b[0m  0.0113\n",
            "      5        \u001b[36m0.0288\u001b[0m       0.7484        \u001b[35m0.0248\u001b[0m  0.0116\n",
            "      6        \u001b[36m0.0227\u001b[0m       0.7484        \u001b[35m0.0200\u001b[0m  0.0119\n",
            "      7        \u001b[36m0.0186\u001b[0m       0.7484        \u001b[35m0.0168\u001b[0m  0.0116\n",
            "      8        \u001b[36m0.0157\u001b[0m       0.7484        \u001b[35m0.0144\u001b[0m  0.0119\n",
            "      9        \u001b[36m0.0136\u001b[0m       0.7484        \u001b[35m0.0126\u001b[0m  0.0117\n",
            "     10        \u001b[36m0.0119\u001b[0m       0.7484        \u001b[35m0.0111\u001b[0m  0.0120\n",
            "     11        \u001b[36m0.0106\u001b[0m       0.7484        \u001b[35m0.0100\u001b[0m  0.0121\n",
            "     12        \u001b[36m0.0095\u001b[0m       0.7484        \u001b[35m0.0090\u001b[0m  0.0128\n",
            "     13        \u001b[36m0.0087\u001b[0m       0.7484        \u001b[35m0.0082\u001b[0m  0.0106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     14        \u001b[36m0.0079\u001b[0m       0.7484        \u001b[35m0.0076\u001b[0m  0.0203\n",
            "     15        \u001b[36m0.0073\u001b[0m       0.7484        \u001b[35m0.0070\u001b[0m  0.0117\n",
            "     16        \u001b[36m0.0068\u001b[0m       0.7484        \u001b[35m0.0065\u001b[0m  0.0166\n",
            "     17        \u001b[36m0.0063\u001b[0m       0.7484        \u001b[35m0.0061\u001b[0m  0.0109\n",
            "     18        \u001b[36m0.0059\u001b[0m       0.7484        \u001b[35m0.0057\u001b[0m  0.0139\n",
            "     19        \u001b[36m0.0055\u001b[0m       0.7484        \u001b[35m0.0054\u001b[0m  0.0129\n",
            "     20        \u001b[36m0.0052\u001b[0m       0.7484        \u001b[35m0.0051\u001b[0m  0.0137\n",
            "     21        \u001b[36m0.0049\u001b[0m       0.7484        \u001b[35m0.0048\u001b[0m  0.0135\n",
            "     22        \u001b[36m0.0047\u001b[0m       0.7484        \u001b[35m0.0046\u001b[0m  0.0143\n",
            "     23        \u001b[36m0.0044\u001b[0m       0.7484        \u001b[35m0.0043\u001b[0m  0.0142\n",
            "     24        \u001b[36m0.0042\u001b[0m       0.7484        \u001b[35m0.0041\u001b[0m  0.0152\n",
            "     25        \u001b[36m0.0040\u001b[0m       0.7484        \u001b[35m0.0040\u001b[0m  0.0157\n",
            "     26        \u001b[36m0.0039\u001b[0m       0.7484        \u001b[35m0.0038\u001b[0m  0.0136\n",
            "     27        \u001b[36m0.0037\u001b[0m       0.7484        \u001b[35m0.0036\u001b[0m  0.0114\n",
            "     28        \u001b[36m0.0035\u001b[0m       0.7484        \u001b[35m0.0035\u001b[0m  0.0125\n",
            "     29        \u001b[36m0.0034\u001b[0m       0.7484        \u001b[35m0.0034\u001b[0m  0.0124\n",
            "     30        \u001b[36m0.0033\u001b[0m       0.7484        \u001b[35m0.0032\u001b[0m  0.0134\n",
            "     31        \u001b[36m0.0032\u001b[0m       0.7484        \u001b[35m0.0031\u001b[0m  0.0117\n",
            "     32        \u001b[36m0.0031\u001b[0m       0.7484        \u001b[35m0.0030\u001b[0m  0.0120\n",
            "     33        \u001b[36m0.0030\u001b[0m       0.7484        \u001b[35m0.0029\u001b[0m  0.0113\n",
            "     34        \u001b[36m0.0029\u001b[0m       0.7484        \u001b[35m0.0028\u001b[0m  0.0121\n",
            "     35        \u001b[36m0.0028\u001b[0m       0.7484        \u001b[35m0.0027\u001b[0m  0.0113\n",
            "     36        \u001b[36m0.0027\u001b[0m       0.7484        \u001b[35m0.0026\u001b[0m  0.0116\n",
            "     37        \u001b[36m0.0026\u001b[0m       0.7484        \u001b[35m0.0026\u001b[0m  0.0110\n",
            "     38        \u001b[36m0.0025\u001b[0m       0.7484        \u001b[35m0.0025\u001b[0m  0.0140\n",
            "     39        \u001b[36m0.0024\u001b[0m       0.7484        \u001b[35m0.0024\u001b[0m  0.0204\n",
            "     40        \u001b[36m0.0024\u001b[0m       0.7484        \u001b[35m0.0024\u001b[0m  0.0113\n",
            "     41        \u001b[36m0.0023\u001b[0m       0.7484        \u001b[35m0.0023\u001b[0m  0.0118\n",
            "     42        \u001b[36m0.0023\u001b[0m       0.7484        \u001b[35m0.0022\u001b[0m  0.0113\n",
            "     43        \u001b[36m0.0022\u001b[0m       0.7484        \u001b[35m0.0022\u001b[0m  0.0179\n",
            "     44        \u001b[36m0.0021\u001b[0m       0.7484        \u001b[35m0.0021\u001b[0m  0.0107\n",
            "     45        \u001b[36m0.0021\u001b[0m       0.7484        \u001b[35m0.0021\u001b[0m  0.0124\n",
            "     46        \u001b[36m0.0020\u001b[0m       0.7484        \u001b[35m0.0020\u001b[0m  0.0135\n",
            "     47        \u001b[36m0.0020\u001b[0m       0.7484        \u001b[35m0.0020\u001b[0m  0.0153\n",
            "     48        \u001b[36m0.0019\u001b[0m       0.7484        \u001b[35m0.0019\u001b[0m  0.0136\n",
            "     49        \u001b[36m0.0019\u001b[0m       0.7484        \u001b[35m0.0019\u001b[0m  0.0148\n",
            "     50        \u001b[36m0.0019\u001b[0m       0.7484        \u001b[35m0.0019\u001b[0m  0.0150\n",
            "     51        \u001b[36m0.0018\u001b[0m       0.7484        \u001b[35m0.0018\u001b[0m  0.0155\n",
            "     52        \u001b[36m0.0018\u001b[0m       0.7484        \u001b[35m0.0018\u001b[0m  0.0157\n",
            "     53        \u001b[36m0.0017\u001b[0m       0.7484        \u001b[35m0.0017\u001b[0m  0.0154\n",
            "     54        \u001b[36m0.0017\u001b[0m       0.7484        \u001b[35m0.0017\u001b[0m  0.0140\n",
            "     55        \u001b[36m0.0017\u001b[0m       0.7484        \u001b[35m0.0017\u001b[0m  0.0132\n",
            "     56        \u001b[36m0.0016\u001b[0m       0.7484        \u001b[35m0.0016\u001b[0m  0.0134\n",
            "     57        \u001b[36m0.0016\u001b[0m       0.7484        \u001b[35m0.0016\u001b[0m  0.0134\n",
            "     58        \u001b[36m0.0016\u001b[0m       0.7484        \u001b[35m0.0016\u001b[0m  0.0113\n",
            "     59        \u001b[36m0.0016\u001b[0m       0.7484        \u001b[35m0.0016\u001b[0m  0.0130\n",
            "     60        \u001b[36m0.0015\u001b[0m       0.7484        \u001b[35m0.0015\u001b[0m  0.0136\n",
            "     61        \u001b[36m0.0015\u001b[0m       0.7484        \u001b[35m0.0015\u001b[0m  0.0121\n",
            "     62        \u001b[36m0.0015\u001b[0m       0.7484        \u001b[35m0.0015\u001b[0m  0.0124\n",
            "     63        \u001b[36m0.0014\u001b[0m       0.7484        \u001b[35m0.0014\u001b[0m  0.0134\n",
            "     64        \u001b[36m0.0014\u001b[0m       0.7484        \u001b[35m0.0014\u001b[0m  0.0162\n",
            "     65        \u001b[36m0.0014\u001b[0m       0.7484        \u001b[35m0.0014\u001b[0m  0.0113\n",
            "     66        \u001b[36m0.0014\u001b[0m       0.7484        \u001b[35m0.0014\u001b[0m  0.0122\n",
            "     67        \u001b[36m0.0014\u001b[0m       0.7484        \u001b[35m0.0014\u001b[0m  0.0119\n",
            "     68        \u001b[36m0.0013\u001b[0m       0.7484        \u001b[35m0.0013\u001b[0m  0.0130\n",
            "     69        \u001b[36m0.0013\u001b[0m       0.7484        \u001b[35m0.0013\u001b[0m  0.0115\n",
            "     70        \u001b[36m0.0013\u001b[0m       0.7484        \u001b[35m0.0013\u001b[0m  0.0115\n",
            "     71        \u001b[36m0.0013\u001b[0m       0.7484        \u001b[35m0.0013\u001b[0m  0.0136\n",
            "     72        \u001b[36m0.0013\u001b[0m       0.7484        \u001b[35m0.0013\u001b[0m  0.0109\n",
            "     73        \u001b[36m0.0012\u001b[0m       0.7484        \u001b[35m0.0012\u001b[0m  0.0115\n",
            "     74        \u001b[36m0.0012\u001b[0m       0.7484        \u001b[35m0.0012\u001b[0m  0.0140\n",
            "     75        \u001b[36m0.0012\u001b[0m       0.7484        \u001b[35m0.0012\u001b[0m  0.0145\n",
            "     76        \u001b[36m0.0012\u001b[0m       0.7484        \u001b[35m0.0012\u001b[0m  0.0136\n",
            "     77        \u001b[36m0.0012\u001b[0m       0.7484        \u001b[35m0.0012\u001b[0m  0.0134\n",
            "     78        \u001b[36m0.0011\u001b[0m       0.7484        \u001b[35m0.0012\u001b[0m  0.0131\n",
            "     79        \u001b[36m0.0011\u001b[0m       0.7484        \u001b[35m0.0011\u001b[0m  0.0124\n",
            "     80        \u001b[36m0.0011\u001b[0m       0.7484        \u001b[35m0.0011\u001b[0m  0.0111\n",
            "     81        \u001b[36m0.0011\u001b[0m       0.7484        \u001b[35m0.0011\u001b[0m  0.0114\n",
            "     82        \u001b[36m0.0011\u001b[0m       0.7484        \u001b[35m0.0011\u001b[0m  0.0129\n",
            "     83        \u001b[36m0.0011\u001b[0m       0.7484        \u001b[35m0.0011\u001b[0m  0.0119\n",
            "     84        \u001b[36m0.0011\u001b[0m       0.7484        \u001b[35m0.0011\u001b[0m  0.0122\n",
            "     85        \u001b[36m0.0010\u001b[0m       0.7484        \u001b[35m0.0010\u001b[0m  0.0115\n",
            "     86        \u001b[36m0.0010\u001b[0m       0.7484        \u001b[35m0.0010\u001b[0m  0.0112\n",
            "     87        \u001b[36m0.0010\u001b[0m       0.7484        \u001b[35m0.0010\u001b[0m  0.0120\n",
            "     88        \u001b[36m0.0010\u001b[0m       0.7484        \u001b[35m0.0010\u001b[0m  0.0125\n",
            "     89        \u001b[36m0.0010\u001b[0m       0.7484        \u001b[35m0.0010\u001b[0m  0.0117\n",
            "     90        \u001b[36m0.0010\u001b[0m       0.7484        \u001b[35m0.0010\u001b[0m  0.0119\n",
            "     91        \u001b[36m0.0010\u001b[0m       0.7484        \u001b[35m0.0010\u001b[0m  0.0121\n",
            "     92        \u001b[36m0.0010\u001b[0m       0.7484        \u001b[35m0.0010\u001b[0m  0.0171\n",
            "     93        \u001b[36m0.0010\u001b[0m       0.7484        \u001b[35m0.0010\u001b[0m  0.0123\n",
            "     94        \u001b[36m0.0009\u001b[0m       0.7484        \u001b[35m0.0009\u001b[0m  0.0125\n",
            "     95        \u001b[36m0.0009\u001b[0m       0.7484        \u001b[35m0.0009\u001b[0m  0.0104\n",
            "     96        \u001b[36m0.0009\u001b[0m       0.7484        \u001b[35m0.0009\u001b[0m  0.0130\n",
            "     97        \u001b[36m0.0009\u001b[0m       0.7484        \u001b[35m0.0009\u001b[0m  0.0134\n",
            "     98        \u001b[36m0.0009\u001b[0m       0.7484        \u001b[35m0.0009\u001b[0m  0.0125\n",
            "     99        \u001b[36m0.0009\u001b[0m       0.7484        \u001b[35m0.0009\u001b[0m  0.0104\n",
            "    100        \u001b[36m0.0009\u001b[0m       0.7484        \u001b[35m0.0009\u001b[0m  0.0118\n",
            "MLP Test Accuracy: 0.7560975609756098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logReg = LogisticRegression()\n",
        "\n",
        "logReg.fit(xtrain, ytrain)\n",
        "print(\"Logistic Regression Test Accuracy:\", logReg.score(xtest, ytest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wWzs_KHirpy",
        "outputId": "94459fcf-02a0-42f8-eff3-082a2d934587"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Test Accuracy: 0.775609756097561\n"
          ]
        }
      ]
    }
  ]
}